{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d77274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-2.0.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[K     |████████████████████████████████| 346 kB 18.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /Users/abhijeet/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/abhijeet/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[K     |████████████████████████████████| 508 kB 29.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Installing collected packages: tzdata, pytz, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Applications/Xcode.app/Contents/Developer/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_a9f7bd1de8e047b49e607c5b435c0625/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_a9f7bd1de8e047b49e607c5b435c0625/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-pip-egg-info-zoa6k0xq\n",
      "         cwd: /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_a9f7bd1de8e047b49e607c5b435c0625/\n",
      "    Complete output (15 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/46/1c/395a83ee7b2d2ad7a05b453872053d41449564477c81dc356f720b16eac4/sklearn-0.0.post12.tar.gz#sha256=54cff9e20839b7b202321178228af4d9388bedf78425d9299fd9ee170d68802e (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post11.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Applications/Xcode.app/Contents/Developer/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_aaf461c1f47d4deea671ba6bb0c625b2/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_aaf461c1f47d4deea671ba6bb0c625b2/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-pip-egg-info-6aw48kui\n",
      "         cwd: /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_aaf461c1f47d4deea671ba6bb0c625b2/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/a4/0b/d1c703256cf293be77b7db44dbef62251fe02a97d0bef981f7120b0b0c0f/sklearn-0.0.post11.tar.gz#sha256=af035c4f0b970b7fc2d3856079aa1aa1032df3d7f65048a9d87114abf13c4629 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post10.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Applications/Xcode.app/Contents/Developer/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_94ea9d132d944c769d6be3aa0ba676ae/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_94ea9d132d944c769d6be3aa0ba676ae/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-pip-egg-info-zo78moji\n",
      "         cwd: /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_94ea9d132d944c769d6be3aa0ba676ae/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b9/0e/b2a4cfaa9e12b9ca4c71507bc26d2c99d75de172c0088c9835a98cf146ff/sklearn-0.0.post10.tar.gz#sha256=d4cd5a2e64b3caaf82cd5e33c46884dfeec5ebf991710d9faeb4fe81cadb3ba6 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Applications/Xcode.app/Contents/Developer/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_b9874b4eedfb476cb7ca854d3982b61d/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_b9874b4eedfb476cb7ca854d3982b61d/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-pip-egg-info-pnus8gnz\n",
      "         cwd: /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_b9874b4eedfb476cb7ca854d3982b61d/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/28/86/207a003339023247fef1bb5bc9f5093140d17294b2f6d15bfcd4885e469e/sklearn-0.0.post9.tar.gz#sha256=1ff5864cf30489ee48a014fe8f4320d7bb59592392a4ef52ae9d7a37942615ac (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post7.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Applications/Xcode.app/Contents/Developer/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_6550258485f545be96bf5d7a11f389e8/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_6550258485f545be96bf5d7a11f389e8/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-pip-egg-info-ftva44_k\n",
      "         cwd: /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_6550258485f545be96bf5d7a11f389e8/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/70/ce/81aa643f3c43488c4a1e417e45f696a61e7ac82b57190fad3c310df2c07b/sklearn-0.0.post7.tar.gz#sha256=1c89020b364fdc3aa2839e0ae34e8f0b406669e4b5c2359dda3ac398f9c76874 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Applications/Xcode.app/Contents/Developer/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_8ebca5c2436e4434898409894063e7c1/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_8ebca5c2436e4434898409894063e7c1/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-pip-egg-info-pm37pxzm\n",
      "         cwd: /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_8ebca5c2436e4434898409894063e7c1/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/7a/93/e0e1b1e98f39dfca7ec9795cb46f6e09e88a2fd5d4a28e4b3d1f618a2aec/sklearn-0.0.post5.tar.gz#sha256=7377c714a03a79bbe9196f435db931fd2a6fa8c68514da7ed3a251fd08c52e2c (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Applications/Xcode.app/Contents/Developer/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_3e230020175044b5a642cf05ee587a5f/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_3e230020175044b5a642cf05ee587a5f/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-pip-egg-info-qn1awva1\n",
      "         cwd: /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_3e230020175044b5a642cf05ee587a5f/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/99/b2/165110013aa66fae6fc13918ad0e9de4801e5f1691d371bf8b63328037e6/sklearn-0.0.post4.tar.gz#sha256=0e81ec9c32d4bb418e7be8f1ec1027d174975502dc84cbc4f4564b4cba31e674 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Applications/Xcode.app/Contents/Developer/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_b5ce5a4def4a465d8c614706dcf8218c/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_b5ce5a4def4a465d8c614706dcf8218c/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-pip-egg-info-bxex19nw\n",
      "         cwd: /private/var/folders/gc/6x3gv3t56szc2732wk2_v14h0000gn/T/pip-install-ii6hf13u/sklearn_b5ce5a4def4a465d8c614706dcf8218c/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/db/1e/af4e9cded5093a92e60d4ae7149a02c7427661b2db66c8ea4d34b17864a2/sklearn-0.0.post1.tar.gz#sha256=76b9ed1623775168657b86b5fe966d45752e5c87f528de6240c38923b94147c5 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp39-cp39-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.0 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.3 MB 14.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 21.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /Users/abhijeet/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sklearn) (2.0.2)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=e2cb62be720282e2d073859fb9011d166968ae0e4312644d8c0cf215c041a122\n",
      "  Stored in directory: /Users/abhijeet/Library/Caches/pip/wheels/e4/7b/98/b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.13.1 sklearn-0.0 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas \n",
    "%pip install sklearn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ddaf923-f7eb-408c-ae66-4c446411e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import BayesianGaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "195c4b4e-cf62-4ce9-9ed9-d1e34c85ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer():\n",
    "    \n",
    "    \"\"\"\n",
    "    Transformer class responsible for processing data to train the CTABGANSynthesizer model\n",
    "    \n",
    "    Variables:\n",
    "    1) train_data -> input dataframe \n",
    "    2) categorical_list -> list of categorical columns\n",
    "    3) mixed_dict -> dictionary of mixed columns\n",
    "    4) n_clusters -> number of modes to fit bayesian gaussian mixture (bgm) model\n",
    "    5) eps -> threshold for ignoring less prominent modes in the mixture model \n",
    "    6) ordering -> stores original ordering for modes of numeric columns\n",
    "    7) output_info -> stores dimension and output activations of columns (i.e., tanh for numeric, softmax for categorical)\n",
    "    8) output_dim -> stores the final column width of the transformed data\n",
    "    9) components -> stores the valid modes used by numeric columns\n",
    "    10) filter_arr -> stores valid indices of continuous component in mixed columns\n",
    "    11) meta -> stores column information corresponding to different data types i.e., categorical/mixed/numerical\n",
    "\n",
    "\n",
    "    Methods:\n",
    "    1) __init__() -> initializes transformer object and computes meta information of columns\n",
    "    2) get_metadata() -> builds an inventory of individual columns and stores their relevant properties\n",
    "    3) fit() -> fits the required bgm models to process the input data\n",
    "    4) transform() -> executes the transformation required to train the model\n",
    "    5) inverse_transform() -> executes the reverse transformation on data generated from the model\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    def __init__(self, train_data=pd.DataFrame, categorical_list=[], mixed_dict={}, n_clusters=10, eps=0.005):\n",
    "        \n",
    "        self.meta = None\n",
    "        self.train_data = train_data\n",
    "        self.categorical_columns= categorical_list\n",
    "        self.mixed_columns= mixed_dict\n",
    "        self.n_clusters = n_clusters\n",
    "        self.eps = eps\n",
    "        self.ordering = []\n",
    "        self.output_info = []\n",
    "        self.output_dim = 0\n",
    "        self.components = []\n",
    "        self.filter_arr = []\n",
    "        self.meta = self.get_metadata()\n",
    "        \n",
    "    def get_metadata(self):\n",
    "        \n",
    "        meta = []\n",
    "    \n",
    "        for index in range(self.train_data.shape[1]):\n",
    "            column = self.train_data.iloc[:,index]\n",
    "            if index in self.categorical_columns:\n",
    "                mapper = column.value_counts().index.tolist()\n",
    "                meta.append({\n",
    "                        \"name\": index,\n",
    "                        \"type\": \"categorical\",\n",
    "                        \"size\": len(mapper),\n",
    "                        \"i2s\": mapper\n",
    "                })\n",
    "            elif index in self.mixed_columns.keys():\n",
    "                meta.append({\n",
    "                    \"name\": index,\n",
    "                    \"type\": \"mixed\",\n",
    "                    \"min\": column.min(),\n",
    "                    \"max\": column.max(),\n",
    "                    \"modal\": self.mixed_columns[index]\n",
    "                })\n",
    "            else:\n",
    "                meta.append({\n",
    "                    \"name\": index,\n",
    "                    \"type\": \"continuous\",\n",
    "                    \"min\": column.min(),\n",
    "                    \"max\": column.max(),\n",
    "                })            \n",
    "\n",
    "        return meta\n",
    "\n",
    "    def fit(self):\n",
    "        \n",
    "        data = self.train_data.values\n",
    "        \n",
    "        # stores the corresponding bgm models for processing numeric data\n",
    "        model = []\n",
    "        \n",
    "        # iterating through column information\n",
    "        for id_, info in enumerate(self.meta):\n",
    "            if info['type'] == \"continuous\":\n",
    "                # fitting bgm model  \n",
    "                gm = BayesianGaussianMixture(\n",
    "                    n_components = self.n_clusters, \n",
    "                    weight_concentration_prior_type='dirichlet_process',\n",
    "                    weight_concentration_prior=0.001, # lower values result in lesser modes being active\n",
    "                    max_iter=100,n_init=1, random_state=42)\n",
    "                gm.fit(data[:, id_].reshape([-1, 1]))\n",
    "                model.append(gm)\n",
    "                # keeping only relevant modes that have higher weight than eps and are used to fit the data\n",
    "                old_comp = gm.weights_ > self.eps\n",
    "                mode_freq = (pd.Series(gm.predict(data[:, id_].reshape([-1, 1]))).value_counts().keys())\n",
    "                comp = []\n",
    "                for i in range(self.n_clusters):\n",
    "                    if (i in (mode_freq)) & old_comp[i]:\n",
    "                        comp.append(True)\n",
    "                    else:\n",
    "                        comp.append(False)\n",
    "                self.components.append(comp) \n",
    "                self.output_info += [(1, 'tanh'), (np.sum(comp), 'softmax')]\n",
    "                self.output_dim += 1 + np.sum(comp)\n",
    "                \n",
    "            elif info['type'] == \"mixed\":\n",
    "                \n",
    "                # in case of mixed columns, two bgm models are used\n",
    "                gm1 = BayesianGaussianMixture(\n",
    "                    self.n_clusters, \n",
    "                    weight_concentration_prior_type='dirichlet_process',\n",
    "                    weight_concentration_prior=0.001, max_iter=100,\n",
    "                    n_init=1,random_state=42)\n",
    "                gm2 = BayesianGaussianMixture(\n",
    "                    self.n_clusters,\n",
    "                    weight_concentration_prior_type='dirichlet_process',\n",
    "                    weight_concentration_prior=0.001, max_iter=100,\n",
    "                    n_init=1,random_state=42)\n",
    "                \n",
    "                # first bgm model is fit to the entire data only for the purposes of obtaining a normalized value of any particular categorical mode\n",
    "                gm1.fit(data[:, id_].reshape([-1, 1]))\n",
    "                \n",
    "                # main bgm model used to fit the continuous component and serves the same purpose as with purely numeric columns\n",
    "                filter_arr = []\n",
    "                for element in data[:, id_]:\n",
    "                    if element not in info['modal']:\n",
    "                        filter_arr.append(True)\n",
    "                    else:\n",
    "                        filter_arr.append(False)\n",
    "                self.filter_arr.append(filter_arr)\n",
    "                \n",
    "                gm2.fit(data[:, id_][filter_arr].reshape([-1, 1]))\n",
    "                \n",
    "                model.append((gm1,gm2))\n",
    "                \n",
    "                # similarly keeping only relevant modes with higher weight than eps and are used to fit strictly continuous data \n",
    "                old_comp = gm2.weights_ > self.eps\n",
    "                mode_freq = (pd.Series(gm2.predict(data[:, id_][filter_arr].reshape([-1, 1]))).value_counts().keys())  \n",
    "                comp = []\n",
    "                  \n",
    "                for i in range(self.n_clusters):\n",
    "                    if (i in (mode_freq)) & old_comp[i]:\n",
    "                        comp.append(True)\n",
    "                    else:\n",
    "                        comp.append(False)\n",
    "\n",
    "                self.components.append(comp)\n",
    "                \n",
    "                # modes of the categorical component are appended to modes produced by the main bgm model\n",
    "                self.output_info += [(1, 'tanh'), (np.sum(comp) + len(info['modal']), 'softmax')]\n",
    "                self.output_dim += 1 + np.sum(comp) + len(info['modal'])\n",
    "            \n",
    "            else:\n",
    "                # in case of categorical columns, bgm model is ignored\n",
    "                model.append(None)\n",
    "                self.components.append(None)\n",
    "                self.output_info += [(info['size'], 'softmax')]\n",
    "                self.output_dim += info['size']\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "    def transform(self, data):\n",
    "        \n",
    "        # stores the transformed values\n",
    "        values = []\n",
    "\n",
    "        # used for accessing filter_arr for transforming mixed columns\n",
    "        mixed_counter = 0\n",
    "        \n",
    "        # iterating through column information\n",
    "        for id_, info in enumerate(self.meta):\n",
    "            current = data[:, id_]\n",
    "            if info['type'] == \"continuous\":\n",
    "                # mode-specific normalization occurs here\n",
    "                current = current.reshape([-1, 1])\n",
    "                # means and stds of the modes are obtained from the corresponding fitted bgm model\n",
    "                means = self.model[id_].means_.reshape((1, self.n_clusters))\n",
    "                stds = np.sqrt(self.model[id_].covariances_).reshape((1, self.n_clusters))\n",
    "                # values are then normalized and stored for all modes\n",
    "                features = np.empty(shape=(len(current),self.n_clusters))\n",
    "                # note 4 is a multiplier to ensure values lie between -1 to 1 but this is not always guaranteed\n",
    "                features = (current - means) / (4 * stds) \n",
    "\n",
    "                # number of distict modes\n",
    "                n_opts = sum(self.components[id_])                \n",
    "                # storing the mode for each data point by sampling from the probability mass distribution across all modes based on fitted bgm model \n",
    "                opt_sel = np.zeros(len(data), dtype='int')\n",
    "                probs = self.model[id_].predict_proba(current.reshape([-1, 1]))\n",
    "                probs = probs[:, self.components[id_]]\n",
    "                for i in range(len(data)):\n",
    "                    pp = probs[i] + 1e-6\n",
    "                    pp = pp / sum(pp)\n",
    "                    opt_sel[i] = np.random.choice(np.arange(n_opts), p=pp)\n",
    "                \n",
    "                # creating a one-hot-encoding for the corresponding selected modes\n",
    "                probs_onehot = np.zeros_like(probs)\n",
    "                probs_onehot[np.arange(len(probs)), opt_sel] = 1\n",
    "\n",
    "                # obtaining the normalized values based on the appropriately selected mode and clipping to ensure values are within (-1,1)\n",
    "                idx = np.arange((len(features)))\n",
    "                features = features[:, self.components[id_]]\n",
    "                features = features[idx, opt_sel].reshape([-1, 1])\n",
    "                features = np.clip(features, -.99, .99) \n",
    "                \n",
    "                # re-ordering the one-hot-encoding of modes in descending order as per their frequency of being selected\n",
    "                re_ordered_phot = np.zeros_like(probs_onehot)  \n",
    "                col_sums = probs_onehot.sum(axis=0)\n",
    "                n = probs_onehot.shape[1]\n",
    "                largest_indices = np.argsort(-1*col_sums)[:n]\n",
    "                for id,val in enumerate(largest_indices):\n",
    "                    re_ordered_phot[:,id] = probs_onehot[:,val]\n",
    "                \n",
    "                # storing the original ordering for invoking inverse transform\n",
    "                self.ordering.append(largest_indices)\n",
    "                \n",
    "                # storing transformed numeric column represented as normalized values and corresponding modes \n",
    "                values += [features, re_ordered_phot]\n",
    "                  \n",
    "            elif info['type'] == \"mixed\":\n",
    "                \n",
    "                # means and standard deviation of modes obtained from the first fitted bgm model\n",
    "                means_0 = self.model[id_][0].means_.reshape([-1])\n",
    "                stds_0 = np.sqrt(self.model[id_][0].covariances_).reshape([-1])\n",
    "\n",
    "                # list to store relevant bgm modes for categorical components\n",
    "                zero_std_list = []\n",
    "                \n",
    "                # means and stds needed to normalize relevant categorical components\n",
    "                means_needed = []\n",
    "                stds_needed = []\n",
    "\n",
    "                # obtaining the closest bgm mode to the categorical component\n",
    "                for mode in info['modal']:\n",
    "                    # skipped for mode representing missing values\n",
    "                    if mode!=-9999999:\n",
    "                        dist = []\n",
    "                        for idx,val in enumerate(list(means_0.flatten())):\n",
    "                            dist.append(abs(mode-val))\n",
    "                        index_min = np.argmin(np.array(dist))\n",
    "                        zero_std_list.append(index_min)\n",
    "                    else: continue\n",
    "\n",
    "                \n",
    "                # stores the appropriate normalized value of categorical modes\n",
    "                mode_vals = []\n",
    "                \n",
    "                # based on the means and stds of the chosen modes for categorical components, their respective values are similarly normalized\n",
    "                for idx in zero_std_list:\n",
    "                    means_needed.append(means_0[idx])\n",
    "                    stds_needed.append(stds_0[idx])\n",
    "               \n",
    "                for i,j,k in zip(info['modal'],means_needed,stds_needed):\n",
    "                    this_val  = np.clip(((i - j) / (4*k)), -.99, .99) \n",
    "                    mode_vals.append(this_val)\n",
    "                \n",
    "                # for categorical modes representing missing values, the normalized value associated is simply 0\n",
    "                if -9999999 in info[\"modal\"]:\n",
    "                    mode_vals.append(0)\n",
    "                \n",
    "                # transforming continuous component of mixed columns similar to purely numeric columns using second fitted bgm model\n",
    "                current = current.reshape([-1, 1])\n",
    "                filter_arr = self.filter_arr[mixed_counter]\n",
    "                current = current[filter_arr]\n",
    "    \n",
    "                means = self.model[id_][1].means_.reshape((1, self.n_clusters))\n",
    "                stds = np.sqrt(self.model[id_][1].covariances_).reshape((1, self.n_clusters))\n",
    "                \n",
    "                features = np.empty(shape=(len(current),self.n_clusters))\n",
    "                features = (current - means) / (4 * stds)\n",
    "                \n",
    "                n_opts = sum(self.components[id_]) \n",
    "                probs = self.model[id_][1].predict_proba(current.reshape([-1, 1]))\n",
    "                probs = probs[:, self.components[id_]]\n",
    "                \n",
    "                opt_sel = np.zeros(len(current), dtype='int')\n",
    "                for i in range(len(current)):\n",
    "                    pp = probs[i] + 1e-6\n",
    "                    pp = pp / sum(pp)\n",
    "                    opt_sel[i] = np.random.choice(np.arange(n_opts), p=pp)\n",
    "                \n",
    "                idx = np.arange((len(features)))\n",
    "                features = features[:, self.components[id_]]\n",
    "                features = features[idx, opt_sel].reshape([-1, 1])\n",
    "                features = np.clip(features, -.99, .99)\n",
    "                \n",
    "                probs_onehot = np.zeros_like(probs)\n",
    "                probs_onehot[np.arange(len(probs)), opt_sel] = 1\n",
    "                \n",
    "                # additional modes are appended to represent categorical component\n",
    "                extra_bits = np.zeros([len(current), len(info['modal'])])\n",
    "                temp_probs_onehot = np.concatenate([extra_bits,probs_onehot], axis = 1)\n",
    "                \n",
    "                # storing the final normalized value and one-hot-encoding of selected modes\n",
    "                final = np.zeros([len(data), 1 + probs_onehot.shape[1] + len(info['modal'])])\n",
    "\n",
    "                # iterates through only the continuous component\n",
    "                features_curser = 0\n",
    "\n",
    "                for idx, val in enumerate(data[:, id_]):\n",
    "                    \n",
    "                    if val in info['modal']:\n",
    "                        # dealing with the modes of categorical component\n",
    "                        category_ = list(map(info['modal'].index, [val]))[0]\n",
    "                        final[idx, 0] = mode_vals[category_]\n",
    "                        final[idx, (category_+1)] = 1\n",
    "                    \n",
    "                    else:\n",
    "                        # dealing with the modes of continuous component\n",
    "                        final[idx, 0] = features[features_curser]\n",
    "                        final[idx, (1+len(info['modal'])):] = temp_probs_onehot[features_curser][len(info['modal']):]\n",
    "                        features_curser = features_curser + 1\n",
    "\n",
    "                # re-ordering the one-hot-encoding of modes in descending order as per their frequency of being selected\n",
    "                just_onehot = final[:,1:]\n",
    "                re_ordered_jhot= np.zeros_like(just_onehot)\n",
    "                n = just_onehot.shape[1]\n",
    "                col_sums = just_onehot.sum(axis=0)\n",
    "                largest_indices = np.argsort(-1*col_sums)[:n]\n",
    "                \n",
    "                for id,val in enumerate(largest_indices):\n",
    "                      re_ordered_jhot[:,id] = just_onehot[:,val]\n",
    "                \n",
    "                final_features = final[:,0].reshape([-1, 1])\n",
    "                \n",
    "                # storing the original ordering for invoking inverse transform\n",
    "                self.ordering.append(largest_indices)\n",
    "                \n",
    "                values += [final_features, re_ordered_jhot]\n",
    "                \n",
    "                mixed_counter = mixed_counter + 1\n",
    "    \n",
    "            else:\n",
    "                # for categorical columns, standard one-hot-encoding is applied where categories are in descending order of frequency by default\n",
    "                self.ordering.append(None)\n",
    "                col_t = np.zeros([len(data), info['size']])\n",
    "                idx = list(map(info['i2s'].index, current))\n",
    "                col_t[np.arange(len(data)), idx] = 1\n",
    "                values.append(col_t)\n",
    "                \n",
    "        return np.concatenate(values, axis=1)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        \n",
    "        # stores the final inverse transformed generated data \n",
    "        data_t = np.zeros([len(data), len(self.meta)])\n",
    "        \n",
    "        # used to iterate through the columns of the raw generated data\n",
    "        st = 0\n",
    "\n",
    "        # iterating through original column information\n",
    "        for id_, info in enumerate(self.meta):\n",
    "            if info['type'] == \"continuous\":\n",
    "                \n",
    "                # obtaining the generated normalized values and clipping for stability\n",
    "                u = data[:, st]\n",
    "                u = np.clip(u, -1, 1)\n",
    "                \n",
    "                # obtaining the one-hot-encoding of the modes representing the normalized values\n",
    "                v = data[:, st + 1:st + 1 + np.sum(self.components[id_])]\n",
    "                \n",
    "                # re-ordering the modes as per their original ordering\n",
    "                order = self.ordering[id_] \n",
    "                v_re_ordered = np.zeros_like(v)\n",
    "                for id,val in enumerate(order):\n",
    "                    v_re_ordered[:,val] = v[:,id]\n",
    "                v = v_re_ordered\n",
    "\n",
    "                # ensuring un-used modes are represented with -100 such that they can be ignored when computing argmax\n",
    "                v_t = np.ones((data.shape[0], self.n_clusters)) * -100\n",
    "                v_t[:, self.components[id_]] = v\n",
    "                v = v_t\n",
    "                \n",
    "                # obtaining approriate means and stds as per the appropriately selected mode for each data point based on fitted bgm model\n",
    "                means = self.model[id_].means_.reshape([-1])\n",
    "                stds = np.sqrt(self.model[id_].covariances_).reshape([-1])\n",
    "                p_argmax = np.argmax(v, axis=1)\n",
    "                std_t = stds[p_argmax]\n",
    "                mean_t = means[p_argmax]\n",
    "                \n",
    "                # executing the inverse transformation \n",
    "                tmp = u * 4 * std_t + mean_t\n",
    "                \n",
    "                data_t[:, id_] = tmp\n",
    "                \n",
    "                # moving to the next set of columns in the raw generated data in correspondance to original column information\n",
    "                st += 1 + np.sum(self.components[id_])\n",
    "                \n",
    "            elif info['type'] == \"mixed\":\n",
    "                \n",
    "                # obtaining the generated normalized values and corresponding modes\n",
    "                u = data[:, st]\n",
    "                u = np.clip(u, -1, 1)\n",
    "                full_v = data[:,(st+1):(st+1)+len(info['modal'])+np.sum(self.components[id_])]\n",
    "                \n",
    "                # re-ordering the modes as per their original ordering\n",
    "                order = self.ordering[id_]\n",
    "                full_v_re_ordered = np.zeros_like(full_v)\n",
    "                for id,val in enumerate(order):\n",
    "                    full_v_re_ordered[:,val] = full_v[:,id]\n",
    "                full_v = full_v_re_ordered                \n",
    "                \n",
    "                # modes of categorical component\n",
    "                mixed_v = full_v[:,:len(info['modal'])]\n",
    "                \n",
    "                # modes of continuous component\n",
    "                v = full_v[:,-np.sum(self.components[id_]):]\n",
    "\n",
    "                # similarly ensuring un-used modes are represented with -100 to be ignored while computing argmax\n",
    "                v_t = np.ones((data.shape[0], self.n_clusters)) * -100\n",
    "                v_t[:, self.components[id_]] = v\n",
    "                v = np.concatenate([mixed_v,v_t], axis=1)       \n",
    "                p_argmax = np.argmax(v, axis=1)\n",
    "\n",
    "                # obtaining the means and stds of the continuous component using second fitted bgm model\n",
    "                means = self.model[id_][1].means_.reshape([-1]) \n",
    "                stds = np.sqrt(self.model[id_][1].covariances_).reshape([-1]) \n",
    "\n",
    "                # used to store the inverse-transformed data points\n",
    "                result = np.zeros_like(u)\n",
    "\n",
    "                for idx in range(len(data)):\n",
    "                    # in case of categorical mode being selected, the mode value itself is simply assigned \n",
    "                    if p_argmax[idx] < len(info['modal']):\n",
    "                        argmax_value = p_argmax[idx]\n",
    "                        result[idx] = float(list(map(info['modal'].__getitem__, [argmax_value]))[0])\n",
    "                    else:\n",
    "                        # in case of continuous mode being selected, similar inverse-transform for purely numeric values is applied\n",
    "                        std_t = stds[(p_argmax[idx]-len(info['modal']))]\n",
    "                        mean_t = means[(p_argmax[idx]-len(info['modal']))]\n",
    "                        result[idx] = u[idx] * 4 * std_t + mean_t\n",
    "            \n",
    "                data_t[:, id_] = result\n",
    "\n",
    "                st += 1 + np.sum(self.components[id_]) + len(info['modal'])\n",
    "                \n",
    "            else:\n",
    "                # reversing one hot encoding back to label encoding for categorical columns \n",
    "                current = data[:, st:st + info['size']]\n",
    "                idx = np.argmax(current, axis=1)\n",
    "                data_t[:, id_] = list(map(info['i2s'].__getitem__, idx))\n",
    "                st += info['size']\n",
    "        return data_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b643c80-9e5a-48bd-be20-f266f4ed8a08",
   "metadata": {},
   "source": [
    "# Improving GMM encoding for continuous value column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb67b62-2b49-4cc5-a2eb-a1d3a086dbf3",
   "metadata": {},
   "source": [
    "Following we give an example of how to use our current gaussian mixture model to encode and decode continuous column. For this test, we have three demands:\n",
    "1. Current test is based on a small dataset. Please scale the code to enable GMM encoding on 1B rows data. This part is actually two sub-tasks (i) read 1B rows data into the algorithm and (ii) scale current GMM method to encode 1B rows data within a reasonable time.\n",
    "2. Properly evaluate the new GMM encoder. Make sure all the values can be inverse transformed. Especially the extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d927f-89ea-42e6-82b8-6c79bc81188c",
   "metadata": {},
   "source": [
    "## Load data and encode column using gaussian mixture method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fc166af-ea89-4844-80a3-fb6e56d718d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../Data/Credit.csv\")[[\"Amount\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22e0c44-b7bb-4f42-b832-aa45fc5b248a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount\n",
       "0   14.61\n",
       "1    1.00\n",
       "2  197.04\n",
       "3    1.00\n",
       "4   23.25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52c78f2-5e51-4548-9d1f-e1ae7660ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhijeet/Library/Python/3.9/lib/python/site-packages/sklearn/mixture/_base.py:270: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transformer = DataTransformer(train_data=train_data)\n",
    "transformer.fit() \n",
    "transformed_train_data = transformer.transform(train_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a2f37-2f1b-45f8-abdb-6d212a9d662b",
   "metadata": {},
   "source": [
    "### Show the encoding for value 14.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8791b6a0-b607-4e86-b8e1-b87817116d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48232937,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4362ca-7963-4e69-9477-16bf1f06085e",
   "metadata": {},
   "source": [
    "## Inverse transform back the encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddee28f2-ff90-460e-b835-b8cb76bc0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_transformed_train_data = transformer.inverse_transform(transformed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15757369-273e-4c0a-aecd-96089bf0571f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.61],\n",
       "       [  1.  ],\n",
       "       [197.04],\n",
       "       ...,\n",
       "       [ 12.  ],\n",
       "       [ 36.  ],\n",
       "       [108.  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_transformed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1d92dd9-6a21-455b-a378-3962337de387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount\n",
       "0   14.61\n",
       "1    1.00\n",
       "2  197.04\n",
       "3    1.00\n",
       "4   23.25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(inverse_transformed_train_data, columns=[\"Amount\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e9e14-b62f-44e8-9994-f205780015cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
